# ğŸ¤– EVA - Enhanced Voice Assistant

EVA is an AI-powered voice assistant built entirely in Python that works **offline** and integrates multiple powerful features:
- ğŸ›ï¸ GUI Dashboard
- âœ‹ Real-Time Gesture Control
- ğŸŒ Multilingual Support
- ğŸ˜Š Facial Recognition & Emotion Detection
- ğŸ“š Offline Knowledge Base with Embedding Search

---

## ğŸš€ Features

| Feature                          | Description                                                                 |
|----------------------------------|-----------------------------------------------------------------------------|
| GUI Dashboard                    | Tkinter-based control panel for EVA's status, logs, and controls            |
| Voice Recognition & Commands     | Use your voice to control apps, websites, system tools, and more           |
| Real-Time Gesture Control        | MediaPipe-based gesture detection for scrolling and clicking                |
| Multilingual Support             | Input/output language translation using Google Translate                    |
| Facial Recognition & Emotion AI | Webcam-based emotion detection using FER and dynamic response adaptation    |
| Offline Knowledge Base           | Query PDF/text documents using FAISS + Sentence Transformers                |

---

## ğŸ§° Installation

### âœ… Requirements
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

### ğŸ“¦ Required Libraries
```
pyttsx3
SpeechRecognition
spacy
wikipedia
pyautogui
pyaudio
googletrans==4.0.0-rc1
opencv-python
mediapipe
fer
faiss-cpu
sentence-transformers
PyMuPDF
tkinter (included with Python)
```

---

## ğŸ’» Running EVA

```bash
python eva.py
```

EVA will launch a GUI, ask your name, preferred language, and begin listening for voice commands.

---

## ğŸ¤ Sample Voice Commands

| Category           | Examples                                           |
|--------------------|----------------------------------------------------|
| System Apps        | "open notepad", "open calculator"                  |
| Web & Wikipedia    | "search browser", "search wikipedia python"        |
| Gesture Control    | "start gesture control" (use hand to scroll/click)|
| Emotion Detection  | "detect my emotion"                                |
| Offline QA         | "load knowledge base", "ask knowledge base"        |
| Multilingual       | Set preferred language to Hindi, Telugu, etc.      |
| Exit               | "exit", or press Exit on GUI                       |

---

## ğŸ§  Offline Document QA (FAISS)
1. Say: **"load knowledge base"** â†’ provide PDF/TXT path
2. Say: **"ask knowledge base"** â†’ ask your question
3. EVA responds from local content without internet

---

## ğŸ§ª Real-Time Gestures
| Gesture         | Action             |
|-----------------|--------------------|
| âœ‹ Open hand     | Activate gesture   |
| ğŸ‘‰ Point up/down | Scroll content     |
| ğŸ¤ Pinch fingers | Click              |

---

## ğŸ˜Š Emotion Detection
EVA uses your webcam to detect:
- happy, sad, angry, neutral, surprise, etc.
And responds empathetically.

---

## ğŸ“ Project Structure
```
EVA/
â”œâ”€â”€ eva.py              # Main assistant script (full integration)
â”œâ”€â”€ requirements.txt    # All dependencies
â”œâ”€â”€ assistant.log       # Activity log
â”œâ”€â”€ README.md           # You're reading it
â”œâ”€â”€ User_Manual.md      # Full usage guide (optional)
```

---

## ğŸ“œ License
**MIT License** â€” free to use, modify, and distribute with credit.

---

## ğŸ‘¨â€ğŸ’» Author
Developed by **YOU** using Python & open-source libraries.

---

## ğŸ“£ Coming Soon
- ğŸµ Media control
- ğŸ’¬ Chat with EVA (LLM)
- ğŸ§© Plugin system
- ğŸ” User authentication

---
